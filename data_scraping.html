<html>
<body>
<div class="sectioninfo">

<p class="page_title">Data Sources : Data Scraped From Edgar and Quandl Data</p>
<p class="section_title">EDGAR DATA : "The Scraped Data"</p>
<br>
<p>
The Edgar API was really difficult to navigate, and there was no obvious way to download 10k documents in bulk via FTP, so we ended up writing a console application in C# that used a web driver see "Edgar Extractor" that invoked FireFox to issue a request to the Edgar server to load company document pages by CIK number. Once we reached the interface, we looped through each page of documents, issuing further requests, until we found "10-K" button, which we did using XPath, and which we invoked the web driver to click on.
At first, we wanted to rely exclusively on parsing of the 10k for our data, but at it turned out, parsing this data was exceedingly difficult, and we only managed to get 25% of the dataset if we were to consider 20+ columns. The parser we built was extremely time-consuming, but ultimately useless. "FinParser.ipynb" contains the useless parser. We looked for alternatives, and found one good one. Excel documents on Edgar, but only for the last 3-5 years.</p>
<p>
We went back to our web driver and clicked through the interactive listing of documents in order to find the excel file with all the financial data we needed in a tabular format, which we copied the address of, and downloaded programatically. After downloading every set of financials for last 3-5 years, we built another console application in C# (because this makes sense, if we're dealing with Microsoft applications) to parse the Excel workbooks, and extracting the relevant financial data. We wrote this data to csv files, which we then converted into one large csv "AllEdgar" using the code you see below.</p>

</div>
</body>
</html>